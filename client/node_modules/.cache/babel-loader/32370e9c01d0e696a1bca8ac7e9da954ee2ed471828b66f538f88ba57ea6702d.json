{"ast":null,"code":"import axios from 'axios';\nconst API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:5000/api';\n\n// Create axios instance with default config\nconst api = axios.create({\n  baseURL: API_BASE_URL,\n  timeout: 30000,\n  headers: {\n    'Content-Type': 'application/json'\n  }\n});\n\n// Request interceptor for logging\napi.interceptors.request.use(config => {\n  var _config$method;\n  console.log('API Request:', (_config$method = config.method) === null || _config$method === void 0 ? void 0 : _config$method.toUpperCase(), config.url);\n  return config;\n}, error => {\n  console.error('API Request Error:', error);\n  return Promise.reject(error);\n});\n\n// Response interceptor for error handling\napi.interceptors.response.use(response => {\n  console.log('API Response:', response.status, response.config.url);\n  return response;\n}, error => {\n  var _error$response, _error$response2, _error$response3, _error$response4;\n  console.error('API Response Error:', (_error$response = error.response) === null || _error$response === void 0 ? void 0 : _error$response.status, ((_error$response2 = error.response) === null || _error$response2 === void 0 ? void 0 : _error$response2.data) || error.message);\n\n  // Handle specific error cases\n  if (((_error$response3 = error.response) === null || _error$response3 === void 0 ? void 0 : _error$response3.status) === 429) {\n    throw new Error('Rate limit exceeded. Please try again later.');\n  }\n  if (((_error$response4 = error.response) === null || _error$response4 === void 0 ? void 0 : _error$response4.status) >= 500) {\n    throw new Error('Server error. Please try again later.');\n  }\n  if (error.code === 'ECONNABORTED') {\n    throw new Error('Request timeout. Please try again.');\n  }\n  throw error;\n});\nexport const scrapingService = {\n  /**\r\n   * Start a new scraping job\r\n   * @param {Object} jobData - The scraping job configuration\r\n   * @param {string[]} jobData.queries - Array of search queries\r\n   * @param {string} jobData.businessType - Type of business to search for\r\n   * @param {string[]} jobData.regions - Array of regions to search in\r\n   * @param {number} jobData.maxResults - Maximum results per query\r\n   * @param {number} jobData.waitTime - Wait time between requests\r\n   * @returns {Promise<Object>} Job information\r\n   */\n  async startScraping(jobData) {\n    try {\n      const response = await api.post('/scraping/start', jobData);\n      return response.data;\n    } catch (error) {\n      var _error$response5, _error$response5$data;\n      console.error('Error starting scraping job:', error);\n      throw new Error(((_error$response5 = error.response) === null || _error$response5 === void 0 ? void 0 : (_error$response5$data = _error$response5.data) === null || _error$response5$data === void 0 ? void 0 : _error$response5$data.error) || 'Failed to start scraping job');\n    }\n  },\n  /**\r\n   * Stop a running scraping job\r\n   * @param {string} jobId - The job ID to stop\r\n   * @returns {Promise<Object>} Success confirmation\r\n   */\n  async stopScraping(jobId) {\n    try {\n      const response = await api.post(`/scraping/stop/${jobId}`);\n      return response.data;\n    } catch (error) {\n      var _error$response6, _error$response6$data;\n      console.error('Error stopping scraping job:', error);\n      throw new Error(((_error$response6 = error.response) === null || _error$response6 === void 0 ? void 0 : (_error$response6$data = _error$response6.data) === null || _error$response6$data === void 0 ? void 0 : _error$response6$data.error) || 'Failed to stop scraping job');\n    }\n  },\n  /**\r\n   * Get the status of a specific scraping job\r\n   * @param {string} jobId - The job ID to check\r\n   * @returns {Promise<Object>} Job status information\r\n   */\n  async getJobStatus(jobId) {\n    try {\n      const response = await api.get(`/scraping/status/${jobId}`);\n      return response.data;\n    } catch (error) {\n      var _error$response7, _error$response7$data;\n      console.error('Error getting job status:', error);\n      throw new Error(((_error$response7 = error.response) === null || _error$response7 === void 0 ? void 0 : (_error$response7$data = _error$response7.data) === null || _error$response7$data === void 0 ? void 0 : _error$response7$data.error) || 'Failed to get job status');\n    }\n  },\n  /**\r\n   * Get all active scraping jobs\r\n   * @returns {Promise<Object[]>} Array of active jobs\r\n   */\n  async getActiveJobs() {\n    try {\n      const response = await api.get('/scraping/jobs');\n      return response.data;\n    } catch (error) {\n      var _error$response8, _error$response8$data;\n      console.error('Error getting active jobs:', error);\n      throw new Error(((_error$response8 = error.response) === null || _error$response8 === void 0 ? void 0 : (_error$response8$data = _error$response8.data) === null || _error$response8$data === void 0 ? void 0 : _error$response8$data.error) || 'Failed to get active jobs');\n    }\n  },\n  /**\r\n   * Check API health\r\n   * @returns {Promise<Object>} Health status\r\n   */\n  async checkHealth() {\n    try {\n      const response = await api.get('/health');\n      return response.data;\n    } catch (error) {\n      console.error('Error checking API health:', error);\n      throw new Error('API health check failed');\n    }\n  }\n};\nexport default scrapingService;","map":{"version":3,"names":["axios","API_BASE_URL","process","env","REACT_APP_API_URL","api","create","baseURL","timeout","headers","interceptors","request","use","config","_config$method","console","log","method","toUpperCase","url","error","Promise","reject","response","status","_error$response","_error$response2","_error$response3","_error$response4","data","message","Error","code","scrapingService","startScraping","jobData","post","_error$response5","_error$response5$data","stopScraping","jobId","_error$response6","_error$response6$data","getJobStatus","get","_error$response7","_error$response7$data","getActiveJobs","_error$response8","_error$response8$data","checkHealth"],"sources":["C:/Users/liamj/Desktop/AI/LeadScraper/client/src/services/scrapingService.js"],"sourcesContent":["import axios from 'axios';\r\n\r\nconst API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:5000/api';\r\n\r\n// Create axios instance with default config\r\nconst api = axios.create({\r\n  baseURL: API_BASE_URL,\r\n  timeout: 30000,\r\n  headers: {\r\n    'Content-Type': 'application/json'\r\n  }\r\n});\r\n\r\n// Request interceptor for logging\r\napi.interceptors.request.use(\r\n  (config) => {\r\n    console.log('API Request:', config.method?.toUpperCase(), config.url);\r\n    return config;\r\n  },\r\n  (error) => {\r\n    console.error('API Request Error:', error);\r\n    return Promise.reject(error);\r\n  }\r\n);\r\n\r\n// Response interceptor for error handling\r\napi.interceptors.response.use(\r\n  (response) => {\r\n    console.log('API Response:', response.status, response.config.url);\r\n    return response;\r\n  },\r\n  (error) => {\r\n    console.error('API Response Error:', error.response?.status, error.response?.data || error.message);\r\n    \r\n    // Handle specific error cases\r\n    if (error.response?.status === 429) {\r\n      throw new Error('Rate limit exceeded. Please try again later.');\r\n    }\r\n    \r\n    if (error.response?.status >= 500) {\r\n      throw new Error('Server error. Please try again later.');\r\n    }\r\n    \r\n    if (error.code === 'ECONNABORTED') {\r\n      throw new Error('Request timeout. Please try again.');\r\n    }\r\n    \r\n    throw error;\r\n  }\r\n);\r\n\r\nexport const scrapingService = {\r\n  /**\r\n   * Start a new scraping job\r\n   * @param {Object} jobData - The scraping job configuration\r\n   * @param {string[]} jobData.queries - Array of search queries\r\n   * @param {string} jobData.businessType - Type of business to search for\r\n   * @param {string[]} jobData.regions - Array of regions to search in\r\n   * @param {number} jobData.maxResults - Maximum results per query\r\n   * @param {number} jobData.waitTime - Wait time between requests\r\n   * @returns {Promise<Object>} Job information\r\n   */\r\n  async startScraping(jobData) {\r\n    try {\r\n      const response = await api.post('/scraping/start', jobData);\r\n      return response.data;\r\n    } catch (error) {\r\n      console.error('Error starting scraping job:', error);\r\n      throw new Error(error.response?.data?.error || 'Failed to start scraping job');\r\n    }\r\n  },\r\n\r\n  /**\r\n   * Stop a running scraping job\r\n   * @param {string} jobId - The job ID to stop\r\n   * @returns {Promise<Object>} Success confirmation\r\n   */\r\n  async stopScraping(jobId) {\r\n    try {\r\n      const response = await api.post(`/scraping/stop/${jobId}`);\r\n      return response.data;\r\n    } catch (error) {\r\n      console.error('Error stopping scraping job:', error);\r\n      throw new Error(error.response?.data?.error || 'Failed to stop scraping job');\r\n    }\r\n  },\r\n\r\n  /**\r\n   * Get the status of a specific scraping job\r\n   * @param {string} jobId - The job ID to check\r\n   * @returns {Promise<Object>} Job status information\r\n   */\r\n  async getJobStatus(jobId) {\r\n    try {\r\n      const response = await api.get(`/scraping/status/${jobId}`);\r\n      return response.data;\r\n    } catch (error) {\r\n      console.error('Error getting job status:', error);\r\n      throw new Error(error.response?.data?.error || 'Failed to get job status');\r\n    }\r\n  },\r\n\r\n  /**\r\n   * Get all active scraping jobs\r\n   * @returns {Promise<Object[]>} Array of active jobs\r\n   */\r\n  async getActiveJobs() {\r\n    try {\r\n      const response = await api.get('/scraping/jobs');\r\n      return response.data;\r\n    } catch (error) {\r\n      console.error('Error getting active jobs:', error);\r\n      throw new Error(error.response?.data?.error || 'Failed to get active jobs');\r\n    }\r\n  },\r\n\r\n  /**\r\n   * Check API health\r\n   * @returns {Promise<Object>} Health status\r\n   */\r\n  async checkHealth() {\r\n    try {\r\n      const response = await api.get('/health');\r\n      return response.data;\r\n    } catch (error) {\r\n      console.error('Error checking API health:', error);\r\n      throw new Error('API health check failed');\r\n    }\r\n  }\r\n};\r\n\r\nexport default scrapingService; "],"mappings":"AAAA,OAAOA,KAAK,MAAM,OAAO;AAEzB,MAAMC,YAAY,GAAGC,OAAO,CAACC,GAAG,CAACC,iBAAiB,IAAI,2BAA2B;;AAEjF;AACA,MAAMC,GAAG,GAAGL,KAAK,CAACM,MAAM,CAAC;EACvBC,OAAO,EAAEN,YAAY;EACrBO,OAAO,EAAE,KAAK;EACdC,OAAO,EAAE;IACP,cAAc,EAAE;EAClB;AACF,CAAC,CAAC;;AAEF;AACAJ,GAAG,CAACK,YAAY,CAACC,OAAO,CAACC,GAAG,CACzBC,MAAM,IAAK;EAAA,IAAAC,cAAA;EACVC,OAAO,CAACC,GAAG,CAAC,cAAc,GAAAF,cAAA,GAAED,MAAM,CAACI,MAAM,cAAAH,cAAA,uBAAbA,cAAA,CAAeI,WAAW,CAAC,CAAC,EAAEL,MAAM,CAACM,GAAG,CAAC;EACrE,OAAON,MAAM;AACf,CAAC,EACAO,KAAK,IAAK;EACTL,OAAO,CAACK,KAAK,CAAC,oBAAoB,EAAEA,KAAK,CAAC;EAC1C,OAAOC,OAAO,CAACC,MAAM,CAACF,KAAK,CAAC;AAC9B,CACF,CAAC;;AAED;AACAf,GAAG,CAACK,YAAY,CAACa,QAAQ,CAACX,GAAG,CAC1BW,QAAQ,IAAK;EACZR,OAAO,CAACC,GAAG,CAAC,eAAe,EAAEO,QAAQ,CAACC,MAAM,EAAED,QAAQ,CAACV,MAAM,CAACM,GAAG,CAAC;EAClE,OAAOI,QAAQ;AACjB,CAAC,EACAH,KAAK,IAAK;EAAA,IAAAK,eAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,gBAAA;EACTb,OAAO,CAACK,KAAK,CAAC,qBAAqB,GAAAK,eAAA,GAAEL,KAAK,CAACG,QAAQ,cAAAE,eAAA,uBAAdA,eAAA,CAAgBD,MAAM,EAAE,EAAAE,gBAAA,GAAAN,KAAK,CAACG,QAAQ,cAAAG,gBAAA,uBAAdA,gBAAA,CAAgBG,IAAI,KAAIT,KAAK,CAACU,OAAO,CAAC;;EAEnG;EACA,IAAI,EAAAH,gBAAA,GAAAP,KAAK,CAACG,QAAQ,cAAAI,gBAAA,uBAAdA,gBAAA,CAAgBH,MAAM,MAAK,GAAG,EAAE;IAClC,MAAM,IAAIO,KAAK,CAAC,8CAA8C,CAAC;EACjE;EAEA,IAAI,EAAAH,gBAAA,GAAAR,KAAK,CAACG,QAAQ,cAAAK,gBAAA,uBAAdA,gBAAA,CAAgBJ,MAAM,KAAI,GAAG,EAAE;IACjC,MAAM,IAAIO,KAAK,CAAC,uCAAuC,CAAC;EAC1D;EAEA,IAAIX,KAAK,CAACY,IAAI,KAAK,cAAc,EAAE;IACjC,MAAM,IAAID,KAAK,CAAC,oCAAoC,CAAC;EACvD;EAEA,MAAMX,KAAK;AACb,CACF,CAAC;AAED,OAAO,MAAMa,eAAe,GAAG;EAC7B;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,MAAMC,aAAaA,CAACC,OAAO,EAAE;IAC3B,IAAI;MACF,MAAMZ,QAAQ,GAAG,MAAMlB,GAAG,CAAC+B,IAAI,CAAC,iBAAiB,EAAED,OAAO,CAAC;MAC3D,OAAOZ,QAAQ,CAACM,IAAI;IACtB,CAAC,CAAC,OAAOT,KAAK,EAAE;MAAA,IAAAiB,gBAAA,EAAAC,qBAAA;MACdvB,OAAO,CAACK,KAAK,CAAC,8BAA8B,EAAEA,KAAK,CAAC;MACpD,MAAM,IAAIW,KAAK,CAAC,EAAAM,gBAAA,GAAAjB,KAAK,CAACG,QAAQ,cAAAc,gBAAA,wBAAAC,qBAAA,GAAdD,gBAAA,CAAgBR,IAAI,cAAAS,qBAAA,uBAApBA,qBAAA,CAAsBlB,KAAK,KAAI,8BAA8B,CAAC;IAChF;EACF,CAAC;EAED;AACF;AACA;AACA;AACA;EACE,MAAMmB,YAAYA,CAACC,KAAK,EAAE;IACxB,IAAI;MACF,MAAMjB,QAAQ,GAAG,MAAMlB,GAAG,CAAC+B,IAAI,CAAC,kBAAkBI,KAAK,EAAE,CAAC;MAC1D,OAAOjB,QAAQ,CAACM,IAAI;IACtB,CAAC,CAAC,OAAOT,KAAK,EAAE;MAAA,IAAAqB,gBAAA,EAAAC,qBAAA;MACd3B,OAAO,CAACK,KAAK,CAAC,8BAA8B,EAAEA,KAAK,CAAC;MACpD,MAAM,IAAIW,KAAK,CAAC,EAAAU,gBAAA,GAAArB,KAAK,CAACG,QAAQ,cAAAkB,gBAAA,wBAAAC,qBAAA,GAAdD,gBAAA,CAAgBZ,IAAI,cAAAa,qBAAA,uBAApBA,qBAAA,CAAsBtB,KAAK,KAAI,6BAA6B,CAAC;IAC/E;EACF,CAAC;EAED;AACF;AACA;AACA;AACA;EACE,MAAMuB,YAAYA,CAACH,KAAK,EAAE;IACxB,IAAI;MACF,MAAMjB,QAAQ,GAAG,MAAMlB,GAAG,CAACuC,GAAG,CAAC,oBAAoBJ,KAAK,EAAE,CAAC;MAC3D,OAAOjB,QAAQ,CAACM,IAAI;IACtB,CAAC,CAAC,OAAOT,KAAK,EAAE;MAAA,IAAAyB,gBAAA,EAAAC,qBAAA;MACd/B,OAAO,CAACK,KAAK,CAAC,2BAA2B,EAAEA,KAAK,CAAC;MACjD,MAAM,IAAIW,KAAK,CAAC,EAAAc,gBAAA,GAAAzB,KAAK,CAACG,QAAQ,cAAAsB,gBAAA,wBAAAC,qBAAA,GAAdD,gBAAA,CAAgBhB,IAAI,cAAAiB,qBAAA,uBAApBA,qBAAA,CAAsB1B,KAAK,KAAI,0BAA0B,CAAC;IAC5E;EACF,CAAC;EAED;AACF;AACA;AACA;EACE,MAAM2B,aAAaA,CAAA,EAAG;IACpB,IAAI;MACF,MAAMxB,QAAQ,GAAG,MAAMlB,GAAG,CAACuC,GAAG,CAAC,gBAAgB,CAAC;MAChD,OAAOrB,QAAQ,CAACM,IAAI;IACtB,CAAC,CAAC,OAAOT,KAAK,EAAE;MAAA,IAAA4B,gBAAA,EAAAC,qBAAA;MACdlC,OAAO,CAACK,KAAK,CAAC,4BAA4B,EAAEA,KAAK,CAAC;MAClD,MAAM,IAAIW,KAAK,CAAC,EAAAiB,gBAAA,GAAA5B,KAAK,CAACG,QAAQ,cAAAyB,gBAAA,wBAAAC,qBAAA,GAAdD,gBAAA,CAAgBnB,IAAI,cAAAoB,qBAAA,uBAApBA,qBAAA,CAAsB7B,KAAK,KAAI,2BAA2B,CAAC;IAC7E;EACF,CAAC;EAED;AACF;AACA;AACA;EACE,MAAM8B,WAAWA,CAAA,EAAG;IAClB,IAAI;MACF,MAAM3B,QAAQ,GAAG,MAAMlB,GAAG,CAACuC,GAAG,CAAC,SAAS,CAAC;MACzC,OAAOrB,QAAQ,CAACM,IAAI;IACtB,CAAC,CAAC,OAAOT,KAAK,EAAE;MACdL,OAAO,CAACK,KAAK,CAAC,4BAA4B,EAAEA,KAAK,CAAC;MAClD,MAAM,IAAIW,KAAK,CAAC,yBAAyB,CAAC;IAC5C;EACF;AACF,CAAC;AAED,eAAeE,eAAe","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}